configfile: "config.yaml"

import pandas as pd
samples = pd.read_csv(config["samples"])

JOBID = config["jobid"]
RAW_SR = config["RAW_SR"]
REFIN: config["REFIN"]
CONTIG_T: config["CONTIG_T"]
P_THRESH: config["P_THRESH"]
krakendb: config["krakendb"]
kraken_level: config["kraken_level"]


(job, part) = glob_wildcards('inter/{JOBID}_diffs{PART}.csv')

rule all:
    input:
      expand("bins/{JOBID}_output_{PART}.csv", JOBID = JOBID, PART = part),
      expand("bins/{JOBID}_parallel_sets_{PART}.csv", JOBID = JOBID, PART = part),
      expand("bins/{JOBID}_parallel_merged.out", JOBID = JOBID)

rule bin_feeder:
    input:
        diffs = 'inter/' + JOBID + '_diffs{PART}.csv'
    output:
        all = "bins/" + JOBID + "_output_{PART}.csv",
    params:
        thresh = P_THRESH, #add this in as a variable at the top later..
        all_diffs = expand("inter/{JOBID}_diffs.csv", JOBID = JOBID)
    conda:
        "envs/py3.yaml"
    shell:
        """
        python scripts/bin_feeder.py {input.diffs} {params.all_diffs} {params.thresh} {output.all}
        """

rule para_sets:
    input:
        bins = "bins/" + JOBID + "_output_{PART}.csv"
    output:
        "bins/" + JOBID + "_parallel_sets_{PART}.csv"
    params:
        thresh = P_THRESH
    conda:
        "envs/py3.yaml"
    shell:
        """
        python scripts/para_sets.py {input.bins} {output} {params.thresh}
        """

rule para_merge:
    input:
        expand("bins/{JOBID}_parallel_sets_{PART}.csv", JOBID=JOBID, PART = part)
    output:
        "bins/{JOBID}_parallel_merged.out"
    resources:
        mem_mb = 64000
    conda:
        "envs/py3.yaml"
    shell:
        """
        python scripts/parallel_merge_step2.py -i {input} -o {output}
        """

rule non_red_step:
    input:
      expand("bins/{JOBID}_parallel_merged.out", JOBID = JOBID)
    output:
      expand("bins/{JOBID}_non_red_list.out", JOBID = JOBID)
    conda:
      "envs/py3.yaml"
    shell:
      """
      python scripts/step3.py {input} {output}
      """
