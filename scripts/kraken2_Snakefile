configfile: "config.yaml"

import pandas as pd
df_samples = pd.read_csv(config["samples"], sep ='\t', index_col = 0)
samples = df_samples["sample"].to_list()

JOBID = config["jobid"]
RAW_SR = config["RAW_SR"]
REFIN = config["REFIN"]
CONTIG_T = config["CONTIG_T"]
P_THRESH = config["P_THRESH"]
krakendb = config["krakendb"]
kraken_level = str(config["kraken_level"])

(CLUSTERS,) = glob_wildcards("output/results/Cluster_{CLUSTER}.csv")

rule all:
    input:
        expand("output/kraken/{JOBID}_Cluster_{CLUSTERS}_kraken.out", JOBID = JOBID, CLUSTERS = CLUSTERS),
        expand("output/kraken/{JOBID}_{kraken_level}_top_kraken.out", JOBID = JOBID, kraken_level = kraken_level),
        "tbl2asn_update.out",
        expand("output/prokka/Cluster_{CLUSTERS}/{JOBID}_{CLUSTERS}.err", JOBID = JOBID, CLUSTERS = CLUSTERS),
        expand("logs/{JOBID}_slurm_prokka.log", JOBID=JOBID),
        "output/results/{JOBID}_seqkit_stats.tsv",
        expand("output/checkm/{JOBID}_checkm.log", JOBID=JOBID)

localrules: kraken_merge, tbl2asn, output, seqkit

rule kraken:
    input:
        "output/results/Cluster_{CLUSTERS}.fasta"
    output:
        report = "output/kraken/{JOBID}_Cluster_{CLUSTERS}_report_kraken.out",
    params:
        db = krakendb,
        output = "output/kraken/{JOBID}_Cluster_{CLUSTERS}_kraken.out"
    conda:
        "../envs/kraken2.yaml"
    threads:
        16
    resources:
        mem_mb = 4000
    shell:
        """
        kraken2 -db {params.db} --threads {threads} --report {output.report} --output {params.output} --use-names {input}
        """

rule kraken_merge:
    input:
        report = expand("output/kraken/{JOBID}_Cluster_{CLUSTERS}_report_kraken.out", JOBID = JOBID, CLUSTERS = CLUSTERS)
    output:
        "output/kraken/{JOBID}_{kraken_level}_top_kraken.out"
    params:
        level = {kraken_level}
    shell:
        """
        cd output/kraken
        find -name '{JOBID}*_report_kraken.out' -type f -printf '\\n%p\\t' -exec sh -c 'echo {{}} | sort -k1nr {{}} | grep -P "\\t{params.level}\\t" | head -n1 ' \\; > {JOBID}_{kraken_level}_top_kraken.out
        """

rule tbl2asn:
    input:
        expand("output/kraken/{JOBID}_{kraken_level}_top_kraken.out", JOBID = JOBID, kraken_level = kraken_level)
    output:
        touch("tbl2asn_update.out")
    conda:
        "../envs/prokka.yaml"
    shell:
        """
        cd $(dirname $(which tbl2asn))
        rm tbl2asn
        wget ftp://ftp.ncbi.nih.gov/toolbox/ncbi_tools/converters/by_program/tbl2asn/linux64*
	gunzip linux64.tbl2asn.gz
	mv linux64.tbl2asn tbl2asn 
        chmod +x tbl2asn
        """

rule prokka:
    input:
        clusters = "output/results/Cluster_{CLUSTERS}.fasta",
        wait = "tbl2asn_update.out"
    output:
        file = "output/prokka/Cluster_{CLUSTERS}/{JOBID}_{CLUSTERS}.err"
    params:
        dir = "output/prokka/Cluster_{CLUSTERS}/",
        prefix = "{JOBID}_{CLUSTERS}",
        prokka = "output/results/Cluster_{CLUSTERS}_short.fasta"
    conda:
        "../envs/prokka.yaml"
    threads:
        20
    shell:
        """
        awk '/^>/{{print substr($1,1,21); next}}{{print}}' < {input.clusters} > {params.prokka}
        prokka {params.prokka} --outdir {params.dir} --prefix {params.prefix} --cpus {threads} --force
        rm {params.prokka}
        """

rule output:
    input: expand("output/prokka/Cluster_{CLUSTERS}/{JOBID}_{CLUSTERS}.err", JOBID = JOBID, CLUSTERS=CLUSTERS)
    output:
        "logs/{JOBID}_slurm_kraken2SM.log"
    shell:
        """
        cat *.out > {output}
        rm *.out
        """

rule seqkit:
    input: wait = expand("logs/{JOBID}_slurm_kraken2SM.log", JOBID = JOBID)
    output:
          "output/results/{JOBID}_seqkit_stats.tsv"
    conda:
        "../envs/py3.yaml"
    threads:
        10
    shell:
        """
        seqkit stats -a -T -j {threads} output/results/*.fasta > {output}
        """

rule checkm:
    input:
        expand("output/results/Cluster_{CLUSTERS}.fasta", CLUSTERS = CLUSTERS),
        expand("output/results/{JOBID}_seqkit_stats.tsv", JOBID=JOBID)
    output:
        expand("output/checkm/{JOBID}_checkm.log", JOBID=JOBID)
    params:
        out = expand("output/checkm", JOBID=JOBID),
        input = "output/results",
        refin = REFIN,
	checkmdb = config["checkm_db_root"]
    threads:
        20
    conda:
        "../envs/checkm.yaml"
    shell:
        """
	checkm_db={params.checkmdb}
	echo ${{checkm_db}} | checkm data setRoot ${{checkm_db}}
        checkm unbinned -x fasta output/results/ {params.refin} output/results/{JOBID}_unbinned_contigs.fa output/results/{JOBID}_unbinned_contigs_stats.tsv
        checkm lineage_wf -f {output} --tab_table -x fasta -t {threads} {params.input} {params.out}
        """
