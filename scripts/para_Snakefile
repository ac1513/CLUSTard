configfile: "config.yaml"

import pandas as pd
df_samples = pd.read_csv(config["samples"], sep ='\t', index_col = 0)
samples = df_samples["sample"].to_list()

JOBID = config["jobid"]
RAW_SR = config["RAW_SR"]
REFIN = config["REFIN"]
CONTIG_T = config["CONTIG_T"]
P_THRESH = config["P_THRESH"]
krakendb = config["krakendb"]
kraken_level = config["kraken_level"]


(job, part) = glob_wildcards('output/clustering/{JOBID}_diffs{PART}.csv')

rule all:
    input:
      expand("output/clustering/{JOBID}_output_{PART}.csv", JOBID = JOBID, PART = part),
      expand("output/clustering/{JOBID}_parallel_sets_{PART}.csv", JOBID = JOBID, PART = part),
      expand("output/clustering/{JOBID}_parallel_merged.out", JOBID = JOBID),
      expand("output/clustering/{JOBID}_non_red_list.out", JOBID = JOBID),
      expand("logs/{JOBID}_para_done.txt", JOBID=JOBID)

rule bin_feeder:
    input:
        diffs = 'output/clustering/' + JOBID + '_diffs{PART}.csv'
    output:
        all = "output/clustering/" + JOBID + "_output_{PART}.csv",
    params:
        thresh = P_THRESH,
        all_diffs = expand("output/clustering/{JOBID}_diffs.csv", JOBID = JOBID)
    conda:
        "../envs/py3.yaml"
    shell:
        """
        python scripts/bin_feeder.py {input.diffs} {params.all_diffs} {params.thresh} {output.all}
        """

rule para_sets:
    input:
        bins = "output/clustering/" + JOBID + "_output_{PART}.csv"
    output:
        "output/clustering/" + JOBID + "_parallel_sets_{PART}.csv"
    params:
        thresh = P_THRESH
    conda:
        "../envs/py3.yaml"
    shell:
        """
        python scripts/para_sets.py {input.bins} {output} {params.thresh}
        """

rule para_merge:
    input:
        expand("output/clustering/{JOBID}_parallel_sets_{PART}.csv", JOBID=JOBID, PART = part)
    output:
        "output/clustering/{JOBID}_parallel_merged.out"
    resources:
        mem_mb = 64000
    conda:
        "../envs/py3.yaml"
    shell:
        """
        python scripts/parallel_merge_step2.py -i {input} -o {output}
        """

rule non_red_step:
    input:
      expand("output/clustering/{JOBID}_parallel_merged.out", JOBID = JOBID)
    output:
      expand("output/clustering/{JOBID}_non_red_list.out", JOBID = JOBID)
    conda:
      "../envs/py3.yaml"
    shell:
      """
      python scripts/step3.py {input} {output}
      """

rule file_parser:
    input:
        expand("output/clustering/{JOBID}_non_red_list.out", JOBID = JOBID)
    output:
        touch("logs/{JOBID}_para_done.txt")
    params:
        contigs = REFIN,
        csv = expand("output/clustering/{JOBID}_read_counts_derived.csv", JOBID = JOBID),
        wd = "results/",
        header = samples
    conda:
        "../envs/py3.yaml"
    shell:
        """
        mkdir -p output/{params.wd}
        python scripts/file_parser.py {params.contigs} {params.csv} {input} {params.wd} -l {params.header}
        """
