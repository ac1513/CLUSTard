configfile: "../config/config.yaml"

JOBID = config["JOBID"] # this can be different from binning pipeline
REFIN = config["REFIN"]
BIN_LOC = config["BIN_LOC"]
kraken_level = config["kraken_level"]
krakendb = config["krakendb"]
checkmdb = config["checkm_db_root"]
GTDB = config["GTDB"]
samples = config["SAMPLES"]
date_scale = config["date_scale"]
plot_order = config["plot_order"]

import pandas as pd
df_samples = pd.read_csv(samples, sep ='\t', index_col = 0)
samples_list = df_samples["sample"].to_list()

gtdb_v_tar_bac = "https://data.ace.uq.edu.au/public/gtdb/data/releases/release95/95.0/bac120_metadata_r95.tar.gz"
gtdb_v_tar_arc = "https://data.ace.uq.edu.au/public/gtdb/data/releases/release95/95.0/ar122_metadata_r95.tar.gz"
gtdb_v_bac = "bac120_metadata_r95.tsv"
gtdb_v_arc = "ar122_metadata_r95.tsv"

if BIN_LOC.endswith("/") == False :
    BIN_LOC = BIN_LOC + "/"

(CLUSTERS,) = glob_wildcards(BIN_LOC + "{CLUSTERS}.fasta")

rule ana_all:
    input:
        expand("analysis/prokka/{JOBID}/{CLUSTERS}/{CLUSTERS}.{ext}", JOBID = JOBID, CLUSTERS = CLUSTERS, ext=[ "err", "fna", "faa", "gff", "gbk", "ffn", "sqn", "fsa", "tbl", "log", "txt", "tsv"]),
        expand("analysis/checkm/{JOBID}/{JOBID}_checkm.log", JOBID=JOBID),
        expand("analysis/{JOBID}_qual_MAGs.txt", JOBID = JOBID),
        expand("analysis/kraken/{JOBID}/{JOBID}_{CLUSTERS}_report_kraken.out", JOBID = JOBID, CLUSTERS = CLUSTERS),
        expand("analysis/kraken/{JOBID}/{JOBID}_{kraken_level}_top_kraken.out", JOBID = JOBID, kraken_level = kraken_level),
        # expand("analysis/kraken/{JOBID}/{JOBID}_{kraken_level}_GTDB_lookup.json", JOBID=JOBID, kraken_level = kraken_level),
        # expand("analysis/{JOBID}_seqkit_stats.tsv", JOBID=JOBID),
        # expand("analysis/plots/{JOBID}_bin_contigs.png", JOBID=JOBID)


rule collate:
    input:
        "logs/{JOBID}_bins.txt"
    output:
        touch(expand("{BIN_LOC}{{CLUSTERS}}.fasta", BIN_LOC=BIN_LOC))

rule prokka:
    input:
        rules.collate.output
    output:
        file = expand("analysis/prokka/{{JOBID}}/{{CLUSTERS}}/{{CLUSTERS}}.{ext}", ext=[ "err", "fna", "faa", "gff", "gbk", "ffn", "sqn", "fsa", "tbl", "log", "txt", "tsv"])
    params:
        dir = "analysis/prokka/{JOBID}/{CLUSTERS}/",
        prefix = "{CLUSTERS}",
        prokka = "results/clusters/{CLUSTERS}_short.fasta"
    conda:
        "envs/prokka.yaml"
    threads:
        20
    shell:
        """
        awk '/^>/{{print substr($1,1,21); next}}{{print}}' < {input.clusters} > {params.prokka}
        prokka {params.prokka} --outdir {params.dir} --prefix {params.prefix} --cpus {threads} --force
        rm {params.prokka}
        """

rule checkm:
  input:
      expand("{BIN_LOC}{CLUSTERS}.fasta", BIN_LOC = BIN_LOC, CLUSTERS = CLUSTERS),
      wait_for = expand("analysis/prokka/{JOBID}/{CLUSTERS}/{CLUSTERS}}.faa", JOBID = JOBID, CLUSTERS = CLUSTERS)
  output:
      log = expand("analysis/checkm/{JOBID}/{JOBID}_checkm.log", JOBID=JOBID),
      stats = expand("analysis/{JOBID}_unbinned_contigs_stats.tsv", JOBID = JOBID)
  params:
      out = expand("analysis/checkm/{JOBID}", JOBID=JOBID),
      input = BIN_LOC,
      refin = REFIN,
      checkmdb = checkmdb,
      jobid = JOBID
  threads:
      20
  conda:
      "envs/checkm.yaml"
  shell:
      """
      checkm_db={params.checkmdb}
      echo ${{checkm_db}} | checkm data setRoot ${{checkm_db}}
      checkm unbinned -x fasta {params.input} {params.refin} analysis/{params.jobid}_unbinned_contigs.fa analysis/{params.jobid}_unbinned_contigs_stats.tsv
      checkm lineage_wf -f {output.log} --tab_table -x fasta -t {threads} {params.input} {params.out}
      """

rule high_mags:
    input:
        prokka = expand("analysis/prokka/{JOBID}/{CLUSTERS}/{CLUSTERS}.{ext}", ext=[ "err", "fna", "faa", "gff", "gbk", "ffn", "sqn", "fsa", "tbl", "log", "txt", "tsv"], CLUSTERS = CLUSTERS, JOBID = JOBID),
        checkm = expand("analysis/checkm/{JOBID}/{JOBID}_checkm.log", JOBID=JOBID)
    output:
        txt = "analysis/{JOBID}_qual_MAGs.txt"
    params:
        prokka = expand("analysis/prokka/{JOBID}/", JOBID = JOBID),
        bin_loc = BIN_LOC,
        jobid = JOBID
    conda :
        "envs/py3.yaml"
    shell:
        """
        python workflow/scripts/python/qual_parse.py {input.checkm} {params.prokka} {params.bin_loc} {params.jobid} > {output.txt}
        """

rule kraken:
    input:
        rules.collate.output
    output:
        report = "analysis/kraken/{JOBID}/{JOBID}_{CLUSTERS}_report_kraken.out",
    params:
        db = krakendb,
        output = "analysis/kraken/{JOBID}/{JOBID}_{CLUSTERS}_kraken.out"
    conda:
        "envs/kraken2.yaml"
    threads:
        16
    resources:
        mem_mb = 4000
    shell:
        """
        kraken2 -db {params.db} --threads {threads} --report {output.report} --output {params.output} --use-names {input.files}
        """

rule kraken_merge:
    input:
        report = expand("analysis/kraken/{JOBID}/{JOBID}_{CLUSTERS}_report_kraken.out", JOBID = JOBID, CLUSTERS = CLUSTERS)
    output:
        "analysis/kraken/{JOBID}/{JOBID}_{kraken_level}_top_kraken.out"
    params:
        level = kraken_level
    shell:
        """
        cd analysis/kraken/{wildcards.JOBID}
        find -name '{wildcards.JOBID}*_report_kraken.out' -type f -printf '\\n%p\\t' -exec sh -c 'echo {{}} | sort -k1nr {{}} | grep "\\t{params.level}\\t" | head -n1 ' \\; > {wildcards.JOBID}_{params.level}_top_kraken.out
        """

if GTDB == "Y":
    rule GTDB_download:
      input:
        kraken_top = expand("analysis/kraken/{JOBID}/{JOBID}_{kraken_level}_top_kraken.out", JOBID = JOBID, kraken_level = kraken_level)
      output:
        bac120_gtdb = temp(expand("tmp/gtdb/{gtdb_v_bac}", gtdb_v_bac = gtdb_v_bac)),
        ar122_gtdb = temp(expand("tmp/gtdb/{gtdb_v_arc}", gtdb_v_arc = gtdb_v_arc))
      params:
        loc = "tmp/gtdb/",
        link_bac = gtdb_v_tar_bac,
        link_arc = gtdb_v_tar_arc
      shell:
        """
        if wget -q --spider {params.link_bac}; then
          wget -O {params.loc}bac120_metadata.tar.gz {params.link_bac}
          tar -xf {params.loc}bac120_metadata.tar.gz -C {params.loc}
        fi

        if wget -q --spider {params.link_arc}; then
          wget -O {params.loc}ar122_metadata.tar.gz {params.link_arc}
          tar -xf {params.loc}ar122_metadata.tar.gz -C {params.loc}
        fi
        """

    rule gtdb_lookup:
      input:
        bac120_gtdb = expand("tmp/gtdb/{gtdb_v_bac}", gtdb_v_bac = gtdb_v_bac),
        ar122_gtdb = expand("tmp/gtdb/{gtdb_v_arc}", gtdb_v_arc = gtdb_v_arc),
        kraken_top = expand("analysis/kraken/{JOBID}/{JOBID}_{kraken_level}_top_kraken.out", JOBID = JOBID, kraken_level = kraken_level)
      output:
        json_lookup = "analysis/kraken/{JOBID}/{JOBID}_{kraken_level}_GTDB_lookup.json"
      params:
        level = {kraken_level}
      conda:
            "envs/py3.yaml"
      shell:
        """
        python workflow/scripts/python/gtdb_lookup.py {input.kraken_top} {params.level} {input.bac120_gtdb} {input.ar122_gtdb} {output.json_lookup}
        """

elif GTDB == "N":
    rule empty_lookup:
      input:
        kraken_top = expand("analysis/kraken/{JOBID}/{JOBID}_{kraken_level}_top_kraken.out", JOBID = JOBID, kraken_level = kraken_level)
      output:
        "analysis/kraken/{JOBID}/{JOBID}_{kraken_level}_GTDB_lookup.json"
      shell:
        """
        touch {output}
        """

rule seqkit:
  input:
      wait_for = expand("analysis/kraken/{JOBID}/{JOBID}_{kraken_level}_GTDB_lookup.json", JOBID = JOBID, kraken_level = kraken_level),
  output:
      "analysis/{JOBID}_seqkit_stats.tsv"
  params:
      binning_loc = BIN_LOC
  conda:
      "envs/py3.yaml"
  threads:
      10
  shell:
      """
      seqkit stats -a -T -j {threads} {params.binning_loc}*.fasta > {output}
      """

rule bin_plot:
    input:
        checkm_unbin = expand("analysis/{JOBID}_unbinned_contigs_stats.tsv", JOBID = JOBID)
    output:
        contig_plot = "analysis/plots/{JOBID}_bin_contigs.png",
        sorted_lengths = "analysis/{JOBID}_sorted_lengths.tsv"
    params:
        binning_dir = BIN_LOC,
        out_loc = "analysis/plots/"
    conda:
        "envs/py3.yaml"
    shell:
        """
        cat {params.binning_dir}*.fasta | awk '$0 ~ ">" {{print c; c=0;printf substr($0,2,100) "\\t"; }} $0 !~ ">" {{c+=length($0);}} END {{ print c; }}' | sort | uniq > {output.sorted_lengths}
        python workflow/scripts/python/bin_plot.py {input.checkm_unbin} {output.sorted_lengths} {params.out_loc} {wildcards.JOBID}
        """
