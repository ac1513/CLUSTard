
configfile: "config/config_analysis.yaml"

JOBID = config["JOBID"] # this can be different from binning pipeline
REFIN = config["REFIN"]
BIN_LOC = config["BIN_LOC"]
kraken_level = config["kraken_level"]
krakendb = config["krakendb"]
GTDB = config["GTDB"]
checkmdb = config["checkm_db_root"]

if BIN_LOC.endswith("/") == False :
    BIN_LOC = BIN_LOC + "/"
print("Location of genome bins: " + BIN_LOC)

# FILE_EX = config["FILE_EX"]
# MAPPING = config["MAPPING"]
# CONTIG_T = config["CONTIG_T"]
# P_THRESH = config["P_THRESH"]
# COUNT_METHOD = config["COUNT_METHOD"]

location = BIN_LOC + "Cluster_{CLUSTER}.fasta"

(CLUSTERS,) = glob_wildcards(location)

rule all:
    input:
        expand("analysis/kraken/{JOBID}_Cluster_{CLUSTERS}_report_kraken.out", JOBID = JOBID, CLUSTERS = CLUSTERS),
        expand("analysis/kraken/{JOBID}_{kraken_level}_top_kraken.out", JOBID = JOBID, kraken_level = kraken_level),
        expand("analysis/prokka/{JOBID}/Cluster_{CLUSTERS}/Cluster_{CLUSTERS}.{ext}", JOBID = JOBID, CLUSTERS = CLUSTERS, ext=[ "err", "fna", "faa", "gff", "gbk", "ffn", "sqn", "fsa", "tbl", "log", "txt", "tsv"]),

localrules: kraken_merge#, output

rule kraken:
    input:
        expand("{BIN_LOC}Cluster_{{CLUSTERS}}.fasta", BIN_LOC=BIN_LOC)
    output:
        report = "analysis/kraken/{JOBID}_Cluster_{CLUSTERS}_report_kraken.out",
    params:
        db = krakendb,
        output = "analysis/kraken/{JOBID}_Cluster_{CLUSTERS}_kraken.out"
    conda:
        "envs/kraken2.yaml"
    threads:
        16
    resources:
        mem_mb = 4000
    shell:
        """
        kraken2 -db {params.db} --threads {threads} --report {output.report} --output {params.output} --use-names {input}
        """

rule kraken_merge:
    input:
        report = expand("analysis/kraken/{JOBID}_Cluster_{CLUSTERS}_report_kraken.out", JOBID = JOBID, CLUSTERS = CLUSTERS)
    output:
        "analysis/kraken/{JOBID}_{kraken_level}_top_kraken.out"
    params:
        level = {kraken_level}
    shell:
        """
        cd analysis/kraken
        find -name '{JOBID}*_report_kraken.out' -type f -printf '\\n%p\\t' -exec sh -c 'echo {{}} | sort -k1nr {{}} | grep -P "\\t{params.level}\\t" | head -n1 ' \\; > {JOBID}_{params.level}_top_kraken.out
        """

rule prokka:
    input:
        clusters = expand("{BIN_LOC}Cluster_{{CLUSTERS}}.fasta", BIN_LOC=BIN_LOC)
    output:
        file = expand("analysis/prokka/{{JOBID}}/Cluster_{{CLUSTERS}}/Cluster_{{CLUSTERS}}.{ext}", ext=[ "err", "fna", "faa", "gff", "gbk", "ffn", "sqn", "fsa", "tbl", "log", "txt", "tsv"])
    params:
        dir = "analysis/prokka/{JOBID}/Cluster_{CLUSTERS}/",
        prefix = "Cluster_{CLUSTERS}",
        prokka = "analysis/clusters/Cluster_{CLUSTERS}_short.fasta"
    conda:
        "envs/prokka.yaml"
    threads:
        20
    shell:
        """
        awk '/^>/{{print substr($1,1,21); next}}{{print}}' < {input.clusters} > {params.prokka}
        prokka {params.prokka} --outdir {params.dir} --prefix {params.prefix} --cpus {threads} --force
        rm {params.prokka}
        """
